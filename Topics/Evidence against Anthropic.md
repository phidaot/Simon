# What are the evidence that Anthropic uses copyrighted books to train their LLM?

## Anthropic Reaches Landmark $1.5 Billion Settlement Over Use of Copyrighted Books in AI Training

**San Francisco, CA** - Anthropic, the prominent artificial intelligence company, has agreed to a landmark $1.5 billion settlement in a class-action lawsuit brought by authors and publishers who alleged that the company used their copyrighted books without permission to train its large language models (LLMs), including its well-known AI assistant, Claude. This settlement, one of the first of its kind in the burgeoning field of generative AI, sheds significant light on the data sourcing practices of major AI labs.

### The Allegations and Evidence of Copyright Infringement

The lawsuit, filed in the U.S. District Court for the Northern District of California, accused Anthropic of engaging in widespread copyright infringement by using vast quantities of copyrighted books to develop its AI models. The central pieces of evidence that emerged during the legal proceedings included:

* **Use of Pirated Datasets:** Court documents revealed that Anthropic downloaded millions of books from illicit online repositories, including the notorious "shadow libraries" **Library Genesis (LibGen)** and the **Pirate Library Mirror**. These websites are known for providing unauthorized access to copyrighted materials.

* **Scale of the Infringement:** It was reported that Anthropic's training data included a massive corpus of literary works, with the lawsuit alleging the use of a significant portion of the collective works of the plaintiff authors and publishers.

### The Court's Ruling: A Split Decision on "Fair Use"

In a pivotal ruling, the federal judge presiding over the case offered a nuanced perspective on the application of copyright law to AI training. The court determined that the act of **training an AI model on copyrighted material could potentially fall under the "fair use" doctrine**. The reasoning was that the use was "transformative," meaning the AI was not simply reproducing the books but was using them to learn patterns and generate new, original content.

However, the judge drew a critical distinction regarding the **acquisition of the training data**. The court ruled that Anthropic's method of obtaining the books through pirate websites was **not protected by fair use**. This distinction is a crucial legal point, suggesting that while the act of training might be permissible under certain conditions, the initial act of obtaining the training data must be lawful.

### The Settlement and Its Implications

While Anthropic did not admit to any wrongdoing as part of the settlement, the substantial financial payout is a significant development in the ongoing legal and ethical debates surrounding AI development. The settlement will establish a fund to compensate the authors and publishers whose works were allegedly used without authorization.

This case and its resolution highlight a significant gray area in current copyright law as it pertains to artificial intelligence. While the "fair use" argument for training AI models received some judicial support, the ruling against the use of pirated source material sends a strong message to AI companies about the importance of legally and ethically sourcing their training data. The outcome of this lawsuit is likely to influence future litigation and may encourage the development of licensing agreements between AI developers and content creators.